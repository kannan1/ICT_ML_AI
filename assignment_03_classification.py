# -*- coding: utf-8 -*-
"""Assignment 03 - Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1knXVe6YPptb2PN2gHNIfT4gTXSDKyv5H
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

df = pd.read_csv('/content/diabetes.csv')

df.head()

# Replace 0 with NaN in all columns except 'Outcome'
df.loc[:, df.columns != 'Outcome'] = df.loc[:, df.columns != 'Outcome'].replace(0, np.nan)

df.head()

df.info()

df.describe()

df.isnull().sum()

"""#Handle Null Values"""

# Replace NaN with mode for specific columns
mode_columns = ['Pregnancies', 'BloodPressure', 'SkinThickness', 'Glucose', 'Insulin']
for col in mode_columns:
    mode_value = df[col].mode()[0]  # mode() returns a Series, [0] gives the most frequent value
    df[col].fillna(mode_value, inplace=True)

# Replace NaN with mean for BMI
df['BMI'].fillna(df['BMI'].mean(), inplace=True)

df.isnull().sum()

df['Outcome'].unique()

"""#Spliting into X and Y"""

x= df.drop('Outcome',axis = 1)
y = df['Outcome']

"""#Split into train and test dataset"""

from sklearn.model_selection import train_test_split
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=.2,random_state=42)

"""#Scaling"""

from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
x_train = sc.fit_transform(x_train)
x_test  = sc.fit_transform(x_test)

"""#Logistic Regression"""

from sklearn.linear_model import LogisticRegression
lr =LogisticRegression()
lr.fit(x_train,y_train)

y_pred = lr.predict(x_test)

y_test

y_pred

#Confusion Matrix
from sklearn.metrics import confusion_matrix,accuracy_score,f1_score,precision_score,recall_score
confusion_matrix(y_test,y_pred)

"""85 - True Positive

35 - True Negative

14 - False positive

20 - False Negative
"""

print(accuracy_score(y_test,y_pred))
print(precision_score(y_test,y_pred))
print(recall_score(y_test,y_pred))
print(f1_score(y_test,y_pred))

"""Accuracy: 0.779 — about 77.9% of total predictions were correct.

Precision: 0.714 — when the model predicted positive, it was correct 71.4% of the time.

Recall (Sensitivity): 0.636 — the model correctly identified 63.6% of all actual positives.

F1 Score: 0.673 — the harmonic mean of precision and recall, giving a balance between the two.

Good overall accuracy (~78%) and precision, which suggests the model is reliable

#KNN
"""

from sklearn.neighbors import KNeighborsClassifier
knn = KNeighborsClassifier(n_neighbors=7)
knn.fit(x_train,y_train)

y_pred_knn = knn.predict(x_test)
accuracy_score(y_test,y_pred_knn)

"""KNN have a Accuracy Score of 68% which is less than LogisticRegression

#SVC
"""

from sklearn.svm import SVC
svm = SVC()
svm.fit(x_train,y_train)

y_pred_svm = svm.predict(x_test)
accuracy_score(y_test,y_pred_svm)

"""SVC have an accuracy of 74.67%

Among the above LogisticRegression have the best performace
"""